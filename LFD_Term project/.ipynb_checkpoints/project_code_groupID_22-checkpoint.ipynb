{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "################################################\n",
    "#\n",
    "# Group 150150104_150160112_150160114_150160152\n",
    "# 150150104 Ece Nur SEN\n",
    "# 150160112 Cenk ERALP\n",
    "# 150160114 Goktug BASARAN\n",
    "# 150160152 Ekin CELEBI\n",
    "#\n",
    "################################################\n",
    "\n",
    "#Importing necessary libraries in order to implement learning models or dimensinality reduction techniques\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor\n",
    "import statsmodels.api as sm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest,mutual_info_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import math\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this will list all files under the input directory\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "\n",
    "#reading the dataset from csv files\n",
    "train_t0 = pd.read_csv(\"train_t0.csv\")\n",
    "train_t1 = pd.read_csv(\"train_t1.csv\")\n",
    "test_t0 = pd.read_csv(\"test_t0.csv\")\n",
    "\n",
    "#this function is for preprocessing the dataset\n",
    "def labelspre(y):\n",
    "    y = np.array(y).copy()\n",
    "    epsilon = 1e-100\n",
    "    for i in range(y.shape[0]):\n",
    "        if(y[i] > 1):\n",
    "            y[i] = 1\n",
    "        if(y[i] < 0):\n",
    "            y[i] = 0\n",
    "        if((1-y[i]) < epsilon): #to avoid overflow in model\n",
    "            y[i] = 1e+10\n",
    "        elif(y[i] < epsilon): #to avoid overflow in model\n",
    "            y[i] = -1e+10\n",
    "        else:\n",
    "            temp = y[i]\n",
    "            y[i] = np.log(temp/(1-temp)) #inverse sigmoid function\n",
    "    return y\n",
    "\n",
    "#this is a function for postprocessing tha dataset\n",
    "def labelspost(y):\n",
    "    y = np.array(y)\n",
    "    for i in range(y.shape[0]):\n",
    "        for j in range(y.shape[1]):\n",
    "            y[i][j] = 1/(1 + np.exp(-y[i][j])) #sigmoid function\n",
    "    return y \n",
    "\n",
    "#this function is for selecting k best feature from given features\n",
    "#it gets features, labels and k as input\n",
    "#returns feature selection model and newly transformed data\n",
    "def KBest(X,y,k):\n",
    "    FSmodel = SelectKBest(mutual_info_regression, k=k).fit(X, y)\n",
    "    new_X = FSmodel.transform(X)\n",
    "    return FSmodel,new_X\n",
    "\n",
    "#this function is for extracting k features from given data\n",
    "#PCA, unsupervised dimensionality reduction technique is used\n",
    "#It gets all features and desired number of features\n",
    "#returns feature extraction model and newly transformed data\n",
    "def FS_PCA(X,k):\n",
    "    pca = PCA(n_components=k)\n",
    "    pca.fit(X)\n",
    "    return pca, pca.transform(X)\n",
    "\n",
    "#this function is for using Random Forest learning model\n",
    "#When the features and labels are given\n",
    "#It returns the learned model\n",
    "def RandomForest(X,y):\n",
    "    return RandomForestRegressor(max_depth=2, random_state=0).fit(X,y)\n",
    "\n",
    "#this function is for using Decision Tree Regression learning model\n",
    "#When the features and labels are given\n",
    "#It returns the learned model\n",
    "def DecisionTree(X,y):\n",
    "    return DecisionTreeRegressor().fit(X,y)\n",
    "\n",
    "#this function is for using Regular Linear Regression learning model\n",
    "#When the features and labels are given\n",
    "#It returns the learned model\n",
    "def regularLinearRegression(X,y):\n",
    "    return LinearRegression().fit(X,y)\n",
    "\n",
    "#this function is for using AdaBoost Regression learning model\n",
    "#When the features and labels are given\n",
    "#It returns the learned model\n",
    "def Adaboost(X,y):\n",
    "    return AdaBoostRegressor(random_state=0, n_estimators=100).fit(X,y)\n",
    "\n",
    "#this function is for using Support Vector Regression learning model\n",
    "#When the features and labels are given\n",
    "#It returns the learned model\n",
    "def SupportVectorRegression(X,y):\n",
    "    return svm.SVR().fit(X,y)\n",
    "\n",
    "#Multioutput Learner Class including features, labels, learned models and dimensionality reduction models\n",
    "class MultioutputLearner:\n",
    "    def __init__(self,X,Y):\n",
    "        epsilon = 1e-100\n",
    "        self.X = np.array(X).copy() #X is the t0 values of dataset\n",
    "        self.Y = np.array(Y).copy() #Y is the t1 values of dataset, they are the future values (labels)\n",
    "        self.listofLR = [] #array for saving learning models, includes 595 learned model, one for every dimension of y(label)\n",
    "        self.listofFS = [] #array for saving dimensionality reduction techniques, includes 595 learned model, one for every dimension of y(label)\n",
    "    \n",
    "    #function for training the dataset\n",
    "    #It takes the multioutput class and desired number of features as input\n",
    "    def train(self,n_features):\n",
    "        for i in range(self.Y.shape[1]): #iterating through 595 brain connectivity t1 values \n",
    "            temp_y = labelspre(self.Y[:,i]).copy() #preprocessing the t1 value\n",
    "            FSmodel,new_X = KBest(self.X, temp_y, n_features) #selecting 'n_features' features in order to decrease the dimesionality \n",
    "            temp_model = SupportVectorRegression(new_X,temp_y) #creating the model\n",
    "            self.listofLR.append(temp_model) #adding learned model to list\n",
    "            self.listofFS.append(FSmodel) #adding dimensionality reduction technique to list\n",
    "\n",
    "    #function for testing the dataset\n",
    "    #It takes the multioutput class and testset of the dataset as input\n",
    "    #returns the predicted t1 values\n",
    "    def test(self,testset):\n",
    "        testoutput = [] #array for saving predicted t1 values\n",
    "        testset = np.array(testset).copy() #changing the testset's type to numpy array\n",
    "        for i in range(len(self.listofLR)): #traversing through learned models\n",
    "            new_test = self.listofFS[i].transform(testset) #applying dimensionality reduction to testset\n",
    "            prediction = self.listofLR[i].predict(new_test).copy() #predicting the t1 values\n",
    "            testoutput.append(prediction) #adding predictions to array\n",
    "        # returning the transpose of predicted values, since appending prediction adds predictions one after other\n",
    "        # but we should add predictions side by sides, hence transpose will provide us the desired format\n",
    "        return np.transpose(labelspost(np.array(testoutput))) \n",
    "\n",
    "#this is a function for testing and training the dataset for kaggle project\n",
    "#It learnes from train data and test on test data\n",
    "#It gets whole dataset, number for folds and numbet of desired features as input\n",
    "#returns the predicted values\n",
    "def TrainandTest_KFold(train_t0, train_t1, test, k,n_features):\n",
    "    #adding train datasets of t0 and t1 values side by side\n",
    "    all_train = np.append( np.delete(np.array(train_t0).copy(), [0], axis=1), np.delete(np.array(train_t1).copy(), [0], axis=1) ,axis=1)\n",
    "    #creating k folds from train datasets\n",
    "    kf = KFold(n_splits=k, shuffle = True, random_state = np.random)\n",
    "    # getting testset without ids\n",
    "    test = np.delete(np.array(test).copy(), [0], axis=1)\n",
    "    #creating an empty test_result array in order to save predictions\n",
    "    testresult = np.zeros((test.shape[0],int(all_train.shape[1]/2)))\n",
    "    #k-fold cross validation\n",
    "    for train_index,test_index in kf.split(all_train):\n",
    "        train_fold = np.array((all_train[train_index])) #getting train fold\n",
    "        fold_t0 = train_fold[:,0:int(train_fold.shape[1]/2)] #getting features of train fold\n",
    "        fold_t1 = train_fold[:,int(train_fold.shape[1]/2):train_fold.shape[1]] #getting labels of train fold\n",
    "        model = MultioutputLearner(fold_t0,fold_t1) #creating the multioutputlearner class from train fold\n",
    "        model.train(n_features) #training the fold\n",
    "        prediction = model.test(test) #testing the fold on testset\n",
    "        testresult += prediction #adding prediction to test results\n",
    "    return testresult/k #taking the averages of prediction to return\n",
    "\n",
    "#this is a function for testing and training the dataset for 5-fold cross validation\n",
    "#It learnes from train folds and test on the remainings\n",
    "#It gets train dataset, number for folds and numbet of desired features as input\n",
    "#returns the mean squared error\n",
    "def TrainandTest_KFold2(train_t0, train_t1, k, n_features):\n",
    "    # adding train datasets of t0 and t1 values side by side\n",
    "    all_train = np.append( np.delete(np.array(train_t0).copy(), [0], axis=1), np.delete(np.array(train_t1).copy(), [0], axis=1) ,axis=1)\n",
    "    #creating k folds from train datasets\n",
    "    kf = KFold(n_splits=k, shuffle = True, random_state = np.random)\n",
    "    #for saving all predictions\n",
    "    total_prediction = np.delete(np.array(train_t0).copy(), [0], axis=1)\n",
    "    #k-fold cross validation\n",
    "    for train_index,test_index in kf.split(all_train):\n",
    "        #getting train fold\n",
    "        train_fold = np.array((all_train[train_index]))\n",
    "        fold_t0 = train_fold[:,0:int(train_fold.shape[1]/2)] #getting features of train fold\n",
    "        fold_t1 = train_fold[:,int(train_fold.shape[1]/2):train_fold.shape[1]] #getting labels of train fold\n",
    "        #getting test fold\n",
    "        test_fold = np.array((all_train[test_index]))\n",
    "        test_fold_t0 = test_fold[:,0:int(test_fold.shape[1]/2)]#getting features of test fold\n",
    "        test_fold_t1 = test_fold[:,int(test_fold.shape[1]/2):test_fold.shape[1]] #getting labels of test fold\n",
    "        #creating the multioutputlearner class from train fold\n",
    "        model = MultioutputLearner(fold_t0,fold_t1) \n",
    "        model.train(n_features) #training the train fold\n",
    "        prediction = model.test(test_fold_t0) #testing the test fold\n",
    "        total_prediction[test_index] = prediction #saving prediction\n",
    "    #calculating the mean squared error between predicted train_t1 values and real train_t1 values\n",
    "    total_error = mean_squared_error(np.delete(np.array(train_t1).copy(), [0], axis=1),total_prediction)\n",
    "    #calculating the pearson correlation between predicted train_t1 values and real train_t1 values\n",
    "    pears_err,p = pearsonr(total_prediction.flatten(),np.delete(np.array(train_t1).copy(), [0], axis=1).flatten())\n",
    "    print(\"Mean Squared Error: \", total_error)\n",
    "    print(\"Pearson Correlation: \",pears_err,\" ~ p-value: \",p)\n",
    "    return total_error #returning mean squared error\n",
    "\n",
    "#for controlling whether we are testing for kaggle or 5-fold cross validation\n",
    "kaggle = False\n",
    "if kaggle == True: #for kaggle, write predictions to submission csv file\n",
    "    testresult = TrainandTest_KFold(train_t0, train_t1, test_t0 , 5, 130).flatten()\n",
    "    samplesubmission = pd.read_csv('sampleSubmission.csv')\n",
    "    output = pd.DataFrame({'ID': samplesubmission.index, 'Predicted': testresult})\n",
    "    output.to_csv('kaggle_submission.csv', index=False)\n",
    "else: #for 5-fold cross validation \n",
    "    TrainandTest_KFold2(train_t0, train_t1 , 5, 130)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
